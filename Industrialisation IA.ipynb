{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81e83003",
   "metadata": {},
   "source": [
    "Preprocessing complet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "271cb605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Chargement des fichiers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CYTech Student\\AppData\\Local\\Temp\\ipykernel_15640\\1676540384.py:9: DtypeWarning: Columns (16,17,29,30,31,126,128,129,132,133,135,138,371) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  test_input_train = pd.read_csv(path_train_input)\n",
      "C:\\Users\\CYTech Student\\AppData\\Local\\Temp\\ipykernel_15640\\1676540384.py:10: DtypeWarning: Columns (16,17,29,30,31,126,128,129,132,133,135,138,371) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  test_input_real = pd.read_csv(path_test_input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó Fusion des inputs...\n",
      "üß¨ Fusion des donn√©es sur 'ID' avec train_output...\n",
      "üéØ S√©paration features / cibles...\n",
      "üîÑ Conversion des colonnes...\n",
      "‚úÇÔ∏è D√©coupage train/test...\n",
      "‚úÖ Preprocessing termin√©.\n",
      " - X final : (479462, 374)\n",
      " - y final : (479462, 2)\n",
      " - X_train : (383610, 374)\n",
      " - X_test  : (95852, 374)\n",
      " - y_train_freq : (383610,)\n",
      " - y_train_cm   : (383610,)\n",
      "\n",
      "üìÇ Colonnes finales utilis√©es (X.columns) :\n",
      "['ID', 'ACTIVIT2', 'VOCATION', 'TYPERS', 'ANCIENNETE', 'ADOSS', 'CARACT1', 'CARACT2', 'CARACT3', 'INDEM1', 'DUREE_REQANEUF', 'CARACT4', 'CARACT5', 'TYPBAT1', 'INDEM2', 'TYPBAT2', 'FRCH1', 'FRCH2', 'DEROG1', 'DEROG2', 'DEROG3', 'DEROG4', 'DEROG5', 'DEROG6', 'DEROG7', 'DEROG8', 'DEROG9', 'DEROG10', 'DEROG11', 'DEROG12', 'DEROG13', 'DEROG14', 'DEROG15', 'DEROG16', 'TAILLE1', 'TAILLE2', 'CA1', 'CA2', 'CA3', 'KAPITAL1', 'KAPITAL2', 'KAPITAL3', 'KAPITAL4', 'KAPITAL5', 'KAPITAL6', 'KAPITAL7', 'KAPITAL8', 'KAPITAL9', 'KAPITAL10', 'KAPITAL11', 'KAPITAL12', 'KAPITAL13', 'KAPITAL14', 'KAPITAL15', 'KAPITAL16', 'KAPITAL17', 'KAPITAL18', 'KAPITAL19', 'KAPITAL20', 'KAPITAL21', 'KAPITAL22', 'KAPITAL23', 'KAPITAL24', 'KAPITAL25', 'KAPITAL26', 'KAPITAL27', 'KAPITAL28', 'KAPITAL29', 'KAPITAL30', 'KAPITAL31', 'KAPITAL32', 'KAPITAL33', 'KAPITAL34', 'KAPITAL35', 'KAPITAL36', 'KAPITAL37', 'KAPITAL38', 'KAPITAL39', 'KAPITAL40', 'KAPITAL41', 'KAPITAL42', 'KAPITAL43', 'SURFACE1', 'SURFACE2', 'SURFACE3', 'SURFACE4', 'SURFACE5', 'SURFACE6', 'SURFACE7', 'SURFACE8', 'SURFACE9', 'SURFACE10', 'SURFACE11', 'SURFACE12', 'SURFACE13', 'SURFACE14', 'SURFACE15', 'SURFACE16', 'SURFACE17', 'SURFACE18', 'SURFACE19', 'SURFACE20', 'SURFACE21', 'NBBAT1', 'NBBAT2', 'NBBAT3', 'NBBAT4', 'NBBAT5', 'NBBAT6', 'NBBAT7', 'NBBAT8', 'NBBAT9', 'NBBAT10', 'NBBAT11', 'NBBAT13', 'NBBAT14', 'TAILLE3', 'TAILLE4', 'NBSINCONJ', 'NBSINSTRT', 'COEFASS', 'RISK1', 'RISK2', 'RISK3', 'RISK4', 'RISK5', 'RISK6', 'RISK7', 'RISK8', 'RISK9', 'RISK10', 'RISK11', 'RISK12', 'RISK13', 'EQUIPEMENT1', 'EQUIPEMENT2', 'EQUIPEMENT3', 'EQUIPEMENT4', 'EQUIPEMENT5', 'EQUIPEMENT6', 'EQUIPEMENT7', 'DISTANCE_111', 'DISTANCE_112', 'DISTANCE_121', 'DISTANCE_122', 'DISTANCE_123', 'DISTANCE_124', 'DISTANCE_131', 'DISTANCE_132', 'DISTANCE_133', 'DISTANCE_141', 'DISTANCE_142', 'DISTANCE_211', 'DISTANCE_212', 'DISTANCE_213', 'DISTANCE_221', 'DISTANCE_222', 'DISTANCE_223', 'DISTANCE_231', 'DISTANCE_242', 'DISTANCE_243', 'DISTANCE_244', 'DISTANCE_311', 'DISTANCE_312', 'DISTANCE_313', 'DISTANCE_321', 'DISTANCE_322', 'DISTANCE_323', 'DISTANCE_324', 'DISTANCE_331', 'DISTANCE_332', 'DISTANCE_333', 'DISTANCE_334', 'DISTANCE_335', 'DISTANCE_411', 'DISTANCE_412', 'DISTANCE_421', 'DISTANCE_422', 'DISTANCE_423', 'DISTANCE_511', 'DISTANCE_512', 'DISTANCE_521', 'DISTANCE_522', 'DISTANCE_523', 'PROPORTION_11', 'PROPORTION_12', 'PROPORTION_13', 'PROPORTION_14', 'PROPORTION_21', 'PROPORTION_22', 'PROPORTION_23', 'PROPORTION_24', 'PROPORTION_31', 'PROPORTION_32', 'PROPORTION_33', 'PROPORTION_41', 'PROPORTION_42', 'PROPORTION_51', 'PROPORTION_52', 'MEN', 'MEN_PAUV', 'MEN_1IND', 'MEN_5IND', 'MEN_PROP', 'MEN_FMP', 'MEN_COLL', 'MEN_MAIS', 'LOG_AVA1', 'LOG_A1_A2', 'LOG_A2_A3', 'LOG_APA3', 'LOG_INC', 'LOG_SOC', 'IND', 'IND_0_Y1', 'IND_Y1_Y2', 'IND_Y2_Y3', 'IND_Y3_Y4', 'IND_Y4_Y5', 'IND_Y5_Y6', 'IND_Y6_Y7', 'IND_Y7_Y8', 'IND_Y8_Y9', 'IND_Y9', 'IND_INC', 'IND_SNV', 'MEN_SURF', 'DISTANCE_1', 'DISTANCE_2', 'ALTITUDE_1', 'ALTITUDE_2', 'ALTITUDE_3', 'ALTITUDE_4', 'ALTITUDE_5', 'BDTOPO_BAT_MAX_HAUTEUR_MAX', 'HAUTEUR', 'HAUTEUR_MAX', 'BDTOPO_BAT_MAX_HAUTEUR', 'ZONE_VENT', 'NB_CASERNES', 'NBJTX25_MM_A', 'NBJTX25_MMAX_A', 'NBJTX25_MSOM_A', 'NBJTX0_MM_A', 'NBJTX0_MMAX_A', 'NBJTX0_MSOM_A', 'NBJTXI27_MM_A', 'NBJTXI27_MMAX_A', 'NBJTXI27_MSOM_A', 'NBJTXS32_MM_A', 'NBJTXS32_MMAX_A', 'NBJTXS32_MSOM_A', 'NBJTXI20_MM_A', 'NBJTXI20_MMAX_A', 'NBJTXI20_MSOM_A', 'NBJTX30_MM_A', 'NBJTX30_MMAX_A', 'NBJTX30_MSOM_A', 'NBJTX35_MM_A', 'NBJTX35_MMAX_A', 'NBJTX35_MSOM_A', 'NBJTN10_MM_A', 'NBJTN10_MMAX_A', 'NBJTN10_MSOM_A', 'NBJTNI10_MM_A', 'NBJTNI10_MMAX_A', 'NBJTNI10_MSOM_A', 'NBJTN5_MM_A', 'NBJTN5_MMAX_A', 'NBJTN5_MSOM_A', 'NBJTNS25_MM_A', 'NBJTNS25_MMAX_A', 'NBJTNS25_MSOM_A', 'NBJTNI15_MM_A', 'NBJTNI15_MMAX_A', 'NBJTNI15_MSOM_A', 'NBJTNI20_MM_A', 'NBJTNI20_MMAX_A', 'NBJTNI20_MSOM_A', 'NBJTNS20_MM_A', 'NBJTNS20_MMAX_A', 'NBJTNS20_MSOM_A', 'NBJTMS24_MM_A', 'NBJTMS24_MMAX_A', 'NBJTMS24_MSOM_A', 'TAMPLIAB_VOR_MM_A', 'TAMPLIAB_VOR_MMAX_A', 'TAMPLIM_VOR_MM_A', 'TAMPLIM_VOR_MMAX_A', 'TM_VOR_MM_A', 'TM_VOR_MMAX_A', 'TMM_VOR_MM_A', 'TMM_VOR_MMAX_A', 'TMMAX_VOR_MM_A', 'TMMAX_VOR_MMAX_A', 'TMMIN_VOR_MM_A', 'TMMIN_VOR_MMAX_A', 'TN_VOR_MM_A', 'TN_VOR_MMAX_A', 'TNAB_VOR_MM_A', 'TNAB_VOR_MMAX_A', 'TNMAX_VOR_MM_A', 'TNMAX_VOR_MMAX_A', 'TX_VOR_MM_A', 'TX_VOR_MMAX_A', 'TXAB_VOR_MM_A', 'TXAB_VOR_MMAX_A', 'TXMIN_VOR_MM_A', 'TXMIN_VOR_MMAX_A', 'NBJFF10_MM_A', 'NBJFF10_MMAX_A', 'NBJFF10_MSOM_A', 'NBJFF16_MM_A', 'NBJFF16_MMAX_A', 'NBJFF16_MSOM_A', 'NBJFF28_MM_A', 'NBJFF28_MMAX_A', 'NBJFF28_MSOM_A', 'NBJFXI3S10_MM_A', 'NBJFXI3S10_MMAX_A', 'NBJFXI3S10_MSOM_A', 'NBJFXI3S16_MM_A', 'NBJFXI3S16_MMAX_A', 'NBJFXI3S16_MSOM_A', 'NBJFXI3S28_MM_A', 'NBJFXI3S28_MMAX_A', 'NBJFXI3S28_MSOM_A', 'NBJFXY8_MM_A', 'NBJFXY8_MMAX_A', 'NBJFXY8_MSOM_A', 'NBJFXY10_MM_A', 'NBJFXY10_MMAX_A', 'NBJFXY10_MSOM_A', 'NBJFXY15_MM_A', 'NBJFXY15_MMAX_A', 'NBJFXY15_MSOM_A', 'FFM_VOR_MM_A', 'FFM_VOR_MMAX_A', 'FXI3SAB_VOR_MM_A', 'FXI3SAB_VOR_MMAX_A', 'FXIAB_VOR_MM_A', 'FXIAB_VOR_MMAX_A', 'FXYAB_VOR_MM_A', 'FXYAB_VOR_MMAX_A', 'FFM_VOR_COM_MM_A_Y', 'FFM_VOR_COM_MMAX_A_Y', 'FXI3SAB_VOR_COM_MM_A_Y', 'FXI3SAB_VOR_COM_MMAX_A_Y', 'NBJRR50_MM_A', 'NBJRR50_MMAX_A', 'NBJRR50_MSOM_A', 'NBJRR1_MM_A', 'NBJRR1_MMAX_A', 'NBJRR1_MSOM_A', 'NBJRR5_MM_A', 'NBJRR5_MMAX_A', 'NBJRR5_MSOM_A', 'NBJRR10_MM_A', 'NBJRR10_MMAX_A', 'NBJRR10_MSOM_A', 'NBJRR30_MM_A', 'NBJRR30_MMAX_A', 'NBJRR30_MSOM_A', 'NBJRR100_MM_A', 'NBJRR100_MMAX_A', 'NBJRR100_MSOM_A', 'RR_VOR_MM_A', 'RR_VOR_MMAX_A', 'RRAB_VOR_MM_A', 'RRAB_VOR_MMAX_A', 'ANNEE_ASSURANCE', 'ESPINSEE', 'AN_EXERC', 'ZONE']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_all(path_train_input: str, path_test_input: str, path_train_output: str, n_train: int = 383610):\n",
    "    \"\"\"\n",
    "    Pr√©traitement simplifi√© sans normalisation, uniquement typage et nettoyage.\n",
    "    \"\"\"\n",
    "    print(\"üì• Chargement des fichiers...\")\n",
    "    test_input_train = pd.read_csv(path_train_input)\n",
    "    test_input_real = pd.read_csv(path_test_input)\n",
    "    train_output = pd.read_csv(path_train_output)\n",
    "\n",
    "    print(\"üîó Fusion des inputs...\")\n",
    "    train_input = pd.concat([test_input_train, test_input_real], ignore_index=True)\n",
    "\n",
    "    print(\"üß¨ Fusion des donn√©es sur 'ID' avec train_output...\")\n",
    "    df = train_input.merge(train_output, on=\"ID\", how=\"left\")\n",
    "\n",
    "    if 'ANNEE_ASSURANCE_x' in df.columns and 'ANNEE_ASSURANCE_y' in df.columns:\n",
    "        df.drop(columns=['ANNEE_ASSURANCE_y'], inplace=True)\n",
    "        df.rename(columns={'ANNEE_ASSURANCE_x': 'ANNEE_ASSURANCE'}, inplace=True)\n",
    "\n",
    "    if \"ZONE\" in df.columns:\n",
    "        df[\"ZONE\"] = df[\"ZONE\"].astype(str).str.strip().astype(\"category\")\n",
    "\n",
    "    print(\"üéØ S√©paration features / cibles...\")\n",
    "    y = df[[\"FREQ\", \"CM\"]].copy()\n",
    "    columns_to_drop = ['FREQ', 'CM', 'CHARGE']\n",
    "    X = df.drop(columns=columns_to_drop, errors='ignore').copy()\n",
    "\n",
    "    print(\"üîÑ Conversion des colonnes...\")\n",
    "    for col in X.columns:\n",
    "        try:\n",
    "            X[col] = pd.to_numeric(X[col], errors='raise')\n",
    "        except:\n",
    "            X[col] = X[col].astype(str).str.strip().astype('category')\n",
    "\n",
    "    print(\"‚úÇÔ∏è D√©coupage train/test...\")\n",
    "    X_train = X.iloc[:n_train].copy()\n",
    "    X_test = X.iloc[n_train:].copy()\n",
    "    y_train_freq = y[\"FREQ\"].iloc[:n_train].copy()\n",
    "    y_train_cm = y[\"CM\"].iloc[:n_train].copy()\n",
    "\n",
    "    print(\"‚úÖ Preprocessing termin√©.\")\n",
    "    print(f\" - X final : {X.shape}\")\n",
    "    print(f\" - y final : {y.shape}\")\n",
    "    print(f\" - X_train : {X_train.shape}\")\n",
    "    print(f\" - X_test  : {X_test.shape}\")\n",
    "    print(f\" - y_train_freq : {y_train_freq.shape}\")\n",
    "    print(f\" - y_train_cm   : {y_train_cm.shape}\")\n",
    "\n",
    "    return X_train, X_test, y_train_freq, y_train_cm, df, X, y\n",
    "\n",
    "X_train, X_test, y_train_freq, y_train_cm, df, X, y = preprocess_all(\n",
    "    \"train_input.csv\",\n",
    "    \"test_input.csv\",\n",
    "    \"train_output.csv\"\n",
    ")\n",
    "\n",
    "print(\"\\nüìÇ Colonnes finales utilis√©es (X.columns) :\")\n",
    "print(list(X.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acdd567",
   "metadata": {},
   "source": [
    "Entrainement des 2 mod√®les"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5e46765f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-30 19:23:39,914] A new study created in memory with name: no-name-c1228c48-bef2-4de4-9147-4b25c25e98c4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Entra√Ænement mod√®le FREQ avec Optuna\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b91e83e8fdf43d78d62aaf53e5a3281",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-30 19:23:45,867] Trial 0 finished with value: -0.05803472418450173 and parameters: {'n_estimators': 83, 'max_depth': 3, 'learning_rate': 0.08232072115459067, 'subsample': 0.8115924296753027, 'colsample_bytree': 0.97925126702631, 'reg_lambda': 4.698061053127093, 'reg_alpha': 0.9817493292084134}. Best is trial 0 with value: -0.05803472418450173.\n",
      "[I 2025-04-30 19:23:49,792] Trial 1 finished with value: -0.006451812457332284 and parameters: {'n_estimators': 58, 'max_depth': 2, 'learning_rate': 0.037891782228211164, 'subsample': 0.7724900397063406, 'colsample_bytree': 0.7436391134922085, 'reg_lambda': 4.895676657464107, 'reg_alpha': 1.1038465624997662}. Best is trial 1 with value: -0.006451812457332284.\n",
      "[I 2025-04-30 19:23:53,765] Trial 2 finished with value: -0.0035343167298584888 and parameters: {'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.026393439474402203, 'subsample': 0.7318781305082679, 'colsample_bytree': 0.7422988409285447, 'reg_lambda': 3.5520049882597124, 'reg_alpha': 1.0795998807221874}. Best is trial 2 with value: -0.0035343167298584888.\n",
      "[I 2025-04-30 19:24:05,047] Trial 3 finished with value: -0.03144503599183446 and parameters: {'n_estimators': 107, 'max_depth': 2, 'learning_rate': 0.033862928478020464, 'subsample': 0.8616561458865664, 'colsample_bytree': 0.8262999224710074, 'reg_lambda': 0.9347035999860565, 'reg_alpha': 0.9515691966278239}. Best is trial 2 with value: -0.0035343167298584888.\n",
      "[I 2025-04-30 19:24:16,478] Trial 4 finished with value: -0.031027825276126797 and parameters: {'n_estimators': 137, 'max_depth': 4, 'learning_rate': 0.09213663265063203, 'subsample': 0.9509647678194804, 'colsample_bytree': 0.7742414312859989, 'reg_lambda': 2.811413799286187, 'reg_alpha': 4.455879012017331}. Best is trial 2 with value: -0.0035343167298584888.\n",
      "[I 2025-04-30 19:24:21,143] Trial 5 finished with value: -0.01647206963238257 and parameters: {'n_estimators': 119, 'max_depth': 3, 'learning_rate': 0.022569872241265942, 'subsample': 0.8737212472908952, 'colsample_bytree': 0.8029747076834753, 'reg_lambda': 2.300819793125641, 'reg_alpha': 4.680284649436261}. Best is trial 2 with value: -0.0035343167298584888.\n",
      "[I 2025-04-30 19:24:27,648] Trial 6 finished with value: -0.04461751330257402 and parameters: {'n_estimators': 87, 'max_depth': 3, 'learning_rate': 0.0753109840101131, 'subsample': 0.909733473706124, 'colsample_bytree': 0.976832181075127, 'reg_lambda': 0.8802901922620976, 'reg_alpha': 4.071875992053347}. Best is trial 2 with value: -0.0035343167298584888.\n",
      "[I 2025-04-30 19:24:36,096] Trial 7 finished with value: -0.09995061147309658 and parameters: {'n_estimators': 108, 'max_depth': 3, 'learning_rate': 0.03874497020635575, 'subsample': 0.9917331793677304, 'colsample_bytree': 0.7262333525309901, 'reg_lambda': 1.6806215427516336, 'reg_alpha': 0.13019916231337858}. Best is trial 2 with value: -0.0035343167298584888.\n",
      "[I 2025-04-30 19:24:46,136] Trial 8 finished with value: -0.04126124764651884 and parameters: {'n_estimators': 137, 'max_depth': 2, 'learning_rate': 0.06735613663111774, 'subsample': 0.9183295436565011, 'colsample_bytree': 0.7209381626795541, 'reg_lambda': 2.4436112805925276, 'reg_alpha': 1.0619669334349329}. Best is trial 2 with value: -0.0035343167298584888.\n",
      "[I 2025-04-30 19:24:56,331] Trial 9 finished with value: -0.038666549162865715 and parameters: {'n_estimators': 129, 'max_depth': 2, 'learning_rate': 0.04183861252893405, 'subsample': 0.9263458735199919, 'colsample_bytree': 0.9824078562457133, 'reg_lambda': 1.5689181934542633, 'reg_alpha': 0.596189844622047}. Best is trial 2 with value: -0.0035343167298584888.\n",
      "‚úÖ Best params FREQ : {'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.026393439474402203, 'subsample': 0.7318781305082679, 'colsample_bytree': 0.7422988409285447, 'reg_lambda': 3.5520049882597124, 'reg_alpha': 1.0795998807221874}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-30 19:25:13,221] A new study created in memory with name: no-name-4a03d5b1-0233-40e8-babf-3cc7972e443d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Entra√Ænement mod√®le CM avec Optuna\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "371eb9ddb2914c2983dfe3ccb1c5bdd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-30 19:25:17,161] Trial 0 finished with value: -0.07532089747462167 and parameters: {'n_estimators': 51, 'max_depth': 5, 'learning_rate': 0.06040529183485253, 'subsample': 0.9327965651059811, 'colsample_bytree': 0.9560267395591965, 'reg_lambda': 3.1752845633728457, 'reg_alpha': 3.616867522552859}. Best is trial 0 with value: -0.07532089747462167.\n",
      "[I 2025-04-30 19:25:24,119] Trial 1 finished with value: -0.25089688261844767 and parameters: {'n_estimators': 61, 'max_depth': 4, 'learning_rate': 0.09871568222045252, 'subsample': 0.9732896497718513, 'colsample_bytree': 0.9611667627782907, 'reg_lambda': 0.6522146805991352, 'reg_alpha': 1.2997466003963516}. Best is trial 0 with value: -0.07532089747462167.\n",
      "[I 2025-04-30 19:25:35,746] Trial 2 finished with value: -0.042154051083769684 and parameters: {'n_estimators': 143, 'max_depth': 2, 'learning_rate': 0.040261361753952604, 'subsample': 0.8747242084742213, 'colsample_bytree': 0.8586726218025633, 'reg_lambda': 1.3097268635254733, 'reg_alpha': 4.774419030638075}. Best is trial 2 with value: -0.042154051083769684.\n",
      "[I 2025-04-30 19:25:44,021] Trial 3 finished with value: -0.023876325161284462 and parameters: {'n_estimators': 79, 'max_depth': 2, 'learning_rate': 0.05284572706019709, 'subsample': 0.7822250138362387, 'colsample_bytree': 0.9918567139930959, 'reg_lambda': 4.437645220852958, 'reg_alpha': 2.707132704793394}. Best is trial 3 with value: -0.023876325161284462.\n",
      "[I 2025-04-30 19:25:52,818] Trial 4 finished with value: -0.12475020599411102 and parameters: {'n_estimators': 121, 'max_depth': 5, 'learning_rate': 0.08391179001764865, 'subsample': 0.7032826332039636, 'colsample_bytree': 0.9368205432581629, 'reg_lambda': 3.7122868363013453, 'reg_alpha': 3.0038359375401957}. Best is trial 3 with value: -0.023876325161284462.\n",
      "[I 2025-04-30 19:25:56,507] Trial 5 finished with value: -0.027161703933931802 and parameters: {'n_estimators': 75, 'max_depth': 3, 'learning_rate': 0.03877057841830329, 'subsample': 0.8615255405039657, 'colsample_bytree': 0.7778506778904684, 'reg_lambda': 3.611696422621435, 'reg_alpha': 3.6404019181864307}. Best is trial 3 with value: -0.023876325161284462.\n",
      "[I 2025-04-30 19:26:00,517] Trial 6 finished with value: -0.02797292648060401 and parameters: {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.02983344736473599, 'subsample': 0.9780821705428953, 'colsample_bytree': 0.981294804334703, 'reg_lambda': 4.662997386667996, 'reg_alpha': 3.2282092119731365}. Best is trial 3 with value: -0.023876325161284462.\n",
      "[I 2025-04-30 19:26:05,479] Trial 7 finished with value: -0.18737573958948694 and parameters: {'n_estimators': 69, 'max_depth': 5, 'learning_rate': 0.05556618101324523, 'subsample': 0.9852325955515358, 'colsample_bytree': 0.7482718895824064, 'reg_lambda': 1.4152599526616987, 'reg_alpha': 1.804579032712289}. Best is trial 3 with value: -0.023876325161284462.\n",
      "[I 2025-04-30 19:26:10,197] Trial 8 finished with value: -0.01373142231364255 and parameters: {'n_estimators': 99, 'max_depth': 4, 'learning_rate': 0.01716838620660785, 'subsample': 0.7944357264417985, 'colsample_bytree': 0.8503742213945272, 'reg_lambda': 4.508663614764662, 'reg_alpha': 4.666569357098434}. Best is trial 8 with value: -0.01373142231364255.\n",
      "[I 2025-04-30 19:26:16,244] Trial 9 finished with value: -0.11910357292875706 and parameters: {'n_estimators': 109, 'max_depth': 5, 'learning_rate': 0.027783886424197518, 'subsample': 0.7968425662059757, 'colsample_bytree': 0.8839709474254009, 'reg_lambda': 1.0926887281945201, 'reg_alpha': 4.042143341492209}. Best is trial 8 with value: -0.01373142231364255.\n",
      "‚úÖ Best params CM : {'n_estimators': 99, 'max_depth': 4, 'learning_rate': 0.01716838620660785, 'subsample': 0.7944357264417985, 'colsample_bytree': 0.8503742213945272, 'reg_lambda': 4.508663614764662, 'reg_alpha': 4.666569357098434}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.utils._testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def train_model_freq(X_train, y_train_freq, X_test):\n",
    "    print(\"üéØ Entra√Ænement mod√®le FREQ avec Optuna\")\n",
    "\n",
    "    # √âchantillonnage\n",
    "    sample_idx = np.random.choice(X_train.index, size=50000, replace=False)\n",
    "    X_sample = X_train.loc[sample_idx]\n",
    "    y_sample = y_train_freq.loc[sample_idx]\n",
    "\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 150),\n",
    "            'max_depth': trial.suggest_int('max_depth', 2, 4),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
    "            'subsample': trial.suggest_float('subsample', 0.7, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.7, 1.0),\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 5.0),\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 5.0),\n",
    "            'random_state': 42,\n",
    "            'enable_categorical': True,\n",
    "            'objective': 'reg:squarederror',\n",
    "            'n_jobs': -1\n",
    "        }\n",
    "        model = XGBRegressor(**params)\n",
    "        return cross_val_score(model, X_sample, y_sample, cv=2, scoring='r2', n_jobs=-1).mean()\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=10, show_progress_bar=True)\n",
    "\n",
    "    print(f\"‚úÖ Best params FREQ : {study.best_params}\")\n",
    "    model = XGBRegressor(**study.best_params, enable_categorical=True, objective='reg:squarederror', random_state=42)\n",
    "    model.fit(X_train, y_train_freq)\n",
    "\n",
    "    # Sauvegarde\n",
    "    with open(\"model_freq.pkl\", \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    return y_pred, model\n",
    "\n",
    "################################################################################################\n",
    "\n",
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def train_model_cm(X_train, y_train_cm, X_test):\n",
    "    print(\"üéØ Entra√Ænement mod√®le CM avec Optuna\")\n",
    "\n",
    "    # √âchantillonnage\n",
    "    sample_size = min(50000, len(X_train))\n",
    "    sample_idx = np.random.choice(X_train.index, size=sample_size, replace=False)\n",
    "    X_sample = X_train.loc[sample_idx]\n",
    "    y_sample = y_train_cm.loc[sample_idx]\n",
    "\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 150),\n",
    "            'max_depth': trial.suggest_int('max_depth', 2, 5),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
    "            'subsample': trial.suggest_float('subsample', 0.7, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.7, 1.0),\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 5.0),\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 5.0),\n",
    "            'enable_categorical': True,\n",
    "            'objective': 'reg:squarederror',\n",
    "            'random_state': 42,\n",
    "            'n_jobs': -1\n",
    "        }\n",
    "        model = XGBRegressor(**params)\n",
    "        return cross_val_score(model, X_sample, y_sample, cv=2, scoring='r2', n_jobs=-1).mean()\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=10, show_progress_bar=True)\n",
    "\n",
    "    print(f\"‚úÖ Best params CM : {study.best_params}\")\n",
    "    model = XGBRegressor(**study.best_params, enable_categorical=True, objective='reg:squarederror', random_state=42)\n",
    "    model.fit(X_train, y_train_cm)\n",
    "\n",
    "    # Sauvegarde\n",
    "    with open(\"model_cm.pkl\", \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    return y_pred, model\n",
    "\n",
    "y_pred_freq, model_freq = train_model_freq(X_train, y_train_freq, X_test)\n",
    "y_pred_cm, model_cm = train_model_cm(X_train, y_train_cm, X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6202fcd7",
   "metadata": {},
   "source": [
    "R√©sultat adapt√© √† un fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1115b31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Chargement des mod√®les...\n",
      "üîç Pr√©traitement des donn√©es...\n",
      "üì• Chargement du fichier √† pr√©dire...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CYTech Student\\AppData\\Local\\Temp\\ipykernel_15640\\2421288777.py:9: DtypeWarning: Columns (16,17,29,30,31,126,128,129,132,133,135,138,371) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  X_new = pd.read_csv(input_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Typage des colonnes...\n",
      "‚úÖ Donn√©es pr√™tes : (95852, 374)\n",
      "üìà Pr√©dictions en cours...\n",
      "üßÆ Construction du DataFrame de sortie...\n",
      "üíæ Sauvegarde dans 'submission.csv'...\n",
      "‚úÖ Fichier g√©n√©r√© avec succ√®s.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "def preprocess_for_prediction(input_path: str):\n",
    "    \"\"\"\n",
    "    Pr√©traitement l√©ger pour pr√©diction (sans normalisation, avec typage).\n",
    "    \"\"\"\n",
    "    print(\"üì• Chargement du fichier √† pr√©dire...\")\n",
    "    X_new = pd.read_csv(input_path)\n",
    "\n",
    "    if 'ANNEE_ASSURANCE_x' in X_new.columns and 'ANNEE_ASSURANCE_y' in X_new.columns:\n",
    "        X_new.drop(columns=['ANNEE_ASSURANCE_y'], inplace=True)\n",
    "        X_new.rename(columns={'ANNEE_ASSURANCE_x': 'ANNEE_ASSURANCE'}, inplace=True)\n",
    "\n",
    "    print(\"üîÑ Typage des colonnes...\")\n",
    "    for col in X_new.columns:\n",
    "        try:\n",
    "            X_new[col] = pd.to_numeric(X_new[col], errors='raise')\n",
    "        except:\n",
    "            X_new[col] = X_new[col].astype(str).str.strip().astype('category')\n",
    "    \n",
    "    if \"ZONE\" in X_new.columns:\n",
    "        X_new[\"ZONE\"] = X_new[\"ZONE\"].astype(str).str.strip().astype(\"category\")\n",
    "\n",
    "    print(f\"‚úÖ Donn√©es pr√™tes : {X_new.shape}\")\n",
    "    return X_new\n",
    "\n",
    "def generate_submission(input_path: str, output_path: str = \"submission.csv\"):\n",
    "    \"\"\"\n",
    "    Fonction compl√®te : chargement des mod√®les, pr√©diction sur donn√©es,\n",
    "    calcul de CHARGE, et sauvegarde en CSV.\n",
    "    \"\"\"\n",
    "    print(\"üì¶ Chargement des mod√®les...\")\n",
    "    with open(\"model_freq.pkl\", \"rb\") as f:\n",
    "        model_freq = pickle.load(f)\n",
    "    with open(\"model_cm.pkl\", \"rb\") as f:\n",
    "        model_cm = pickle.load(f)\n",
    "\n",
    "    print(\"üîç Pr√©traitement des donn√©es...\")\n",
    "    X_to_predict = preprocess_for_prediction(input_path)\n",
    "\n",
    "    print(\"üìà Pr√©dictions en cours...\")\n",
    "    y_pred_freq = model_freq.predict(X_to_predict)\n",
    "    y_pred_cm = model_cm.predict(X_to_predict)\n",
    "\n",
    "    print(\"üßÆ Construction du DataFrame de sortie...\")\n",
    "    df_submission = pd.DataFrame({\n",
    "        \"ID\": X_to_predict[\"ID\"],\n",
    "        \"FREQ\": y_pred_freq,\n",
    "        \"CM\": y_pred_cm,\n",
    "        \"ANNEE_ASSURANCE\": X_to_predict[\"ANNEE_ASSURANCE\"]\n",
    "    })\n",
    "    df_submission[\"CHARGE\"] = df_submission[\"FREQ\"] * df_submission[\"CM\"] * df_submission[\"ANNEE_ASSURANCE\"]\n",
    "\n",
    "    print(f\"üíæ Sauvegarde dans '{output_path}'...\")\n",
    "    df_submission.to_csv(output_path, index=False)\n",
    "    print(\"‚úÖ Fichier g√©n√©r√© avec succ√®s.\")\n",
    "\n",
    "generate_submission(\"test_input.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "019d6bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CYTech Student\\AppData\\Local\\Temp\\ipykernel_15640\\1810994165.py:4: DtypeWarning: Columns (16,17,29,30,31,126,128,129,132,133,135,138,371) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"test_input.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Nouveau fichier 'test_input_for_API.csv' cr√©√© avec 1000 lignes.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charge le fichier complet\n",
    "df = pd.read_csv(\"test_input.csv\")\n",
    "\n",
    "# Prend seulement les 1000 premi√®res lignes\n",
    "df_small = df.head(1000)\n",
    "\n",
    "# Sauvegarde dans un nouveau fichier\n",
    "df_small.to_csv(\"test_input_for_API.csv\", index=False)\n",
    "\n",
    "print(\"‚úÖ Nouveau fichier 'test_input_for_API.csv' cr√©√© avec 1000 lignes.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
